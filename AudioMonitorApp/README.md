# AudioMonitorApp  
A professionalâ€‘grade realâ€‘time audio input monitor built for **macOS 16 (26.x)** using **Swift 6.2**, th latest Swift Concurrency model, and SwiftUI.  

AudioMonitorApp is engineered to handle complex CoreAudio & HAL behavior, highâ€‘precision metering, and unstable Bluetooth audio routes (AirPods, Beats) â€” all while maintaining accurate, stable, lowâ€‘latency audio monitoring.

## âœ¨ Features

### ğŸšï¸ Accurate, Professional VU Metering
- Realâ€‘time **dBFS** measurement (L/R)  
- Analogâ€‘style ballistic behavior (fast attack / slow release)  
- Needleâ€‘like response curve modeled after 1970s hardware  
- Stereo processing (or mono if device reports it)  
- Overmodulation detection (clip indicator shown in red)  
- Silence detection & noiseâ€‘floor learning  
- â€“120 dBFS safety floor for unstable devices (Bluetooth warmâ€‘up)

### ğŸ§ Advanced Input Device Management

Powered by a custom **AudioManager** built on AVAudioEngine + CoreAudio HAL:

- Live monitoring of **system default input**  
- Grace windows preventing rapid reconfiguration  
- Intelligent **Bluetooth warmâ€‘up** (200â€“600 ms buffering)  
- Recovery from HAL failures:
  - `!obj`
  - `!dev`
  - `-10877` (AudioUnit render warning)
  - `TooManyFramesToProcess`
- Fully clean teardown and safe engine restarts  
- Removes taps before installing new ones  
- Learns perâ€‘device noise floors  


### ğŸ©º Diagnostics & Logging

Includes a full inâ€‘app diagnostics suite:

- Realâ€‘time log stream  
- Deviceâ€‘change timeline  
- State machine transitions  
- AVAudioEngine event visibility  
- HAL error codes surfaced clearly  
- Bluetooth warmâ€‘up tracking  
- Perâ€‘frame AudioStats  
- Searchable, scrollable **AdvancedLogViewerView**


### ğŸ“Š Real-Time Audio Processing (AudioProcessor.swift)

- dBFS computation per channel  
- Attack/release smoothing  
- Zeroâ€‘crossing peak verification  
- Adaptive noiseâ€‘floor logic  
- Silence & clipping detection  
- Bluetooth stabilization mode  
- Safety clamp at **â€“120 dBFS** when device is unstable


### âš¡ Modern Swift Concurrency (Swift 6.2)

This project is fully updated for the new Swift 6.2 requirements:

- Strict **Sendable** enforcement  
- Isolation domains (MainActor, audio thread isolation)  
- Async device polling  
- Actorâ€‘safe logging system  
- Nonisolated audio callback paths  
- Avoids undefined behavior across threads


## ğŸ§± Architecture Overview (MVVM + Audio Layer)

### **Model**
- `AudioStats`  
- `AudioDeviceInfo`  
- `LogEntry`  
- `AudioProcessor`  
- `LogManager`  

### **ViewModel**
- `AudioMonitorViewModel`
  - Owns `AudioManager`
  - Publishes device list & active device
  - Publishes VU levels
  - Coordinates logging, stabilization, warmâ€‘up
  - Provides UIâ€‘ready state

### **View**
- `AudioMonitorView`
- `AdvancedLogViewerView`
- `AudioStatsView`
- (Future) macOS Widget

## ğŸ§ How Audio Input Works

### 1. AVAudioEngine Input Tap
The engine pulls PCM buffers â†’ AudioProcessor computes realâ€‘time levels.

### 2. Device Switching Pipeline
When macOS changes the **default input**:

1. Detect CoreAudio notification  
2. Freeze UI selection unless user pinned a device  
3. Apply graceâ€‘window (200â€“600 ms)  
4. Quiesce engine  
5. Remove tap  
6. Install new tap  
7. Begin noiseâ€‘floor learning  
8. Resume monitoring

Bluetooth devices get an extended warmâ€‘up window.

### 3. HAL Error Recovery

The app catches and survives:

| Error | Meaning |
|-------|---------|
| `!obj` | HAL object vanished midâ€‘transaction |
| `!dev` | Device disappeared while IOProc active |
| `-10877` | Render callback produced invalid audio |
| `TooManyFramesToProcess` | Engine forced into oversized render cycle |

Engine is restarted safely, with structured logging.

### 4. Adaptive Noise Floor Learning
Noise floor is learned during first valid frames.  
Until stable: all frames are forced to **â€“120 dBFS**.


## ğŸ§ª Debugging Tools

### Inline Live Log Viewer
Displays:

- systemDefaultInput events  
- HAL warnings  
- Audio engine restarts  
- Bluetooth device warmâ€‘up timeline  
- Tap failures  
- Perâ€‘frame statistical summaries  

### Persistent Logs
Saved automatically for later review.


## ğŸ“¦ Project Structure

```
AudioMonitorApp/
 â”œâ”€â”€ AudioManager.swift
 â”œâ”€â”€ AudioProcessor.swift
 â”œâ”€â”€ AudioMonitorViewModel.swift
 â”œâ”€â”€ LogManager.swift
 â”œâ”€â”€ LogWriter.swift
 â”œâ”€â”€ AudioMonitorView.swift
 â”œâ”€â”€ AdvancedLogViewerView.swift
 â”œâ”€â”€ AudioStatsView.swift
 â”œâ”€â”€ AudioMonitorApp.swift
 â””â”€â”€ README.md
```


## ğŸ›  Build Requirements
- **macOS 16 (26.x)**  
- **Xcode 16+**  
- **Swift 6.2**  
- SwiftUI  
- Microphone permission  


## ğŸš€ Roadmap
- macOS widget (live dBFS meter)  
- Historical graphing + export  
- LUFS/RMS DSP modes  
- Log export  
- Test suite for DSP & AudioManager  


## ğŸ“„ License
MIT (customize if needed)


## ğŸ¤ Contributions
Open to PRs and issues.


## ğŸ§¡ About This Project
AudioMonitorApp is built as a **professional diagnostic tool** for engineers, musicians, podcasters, and developers who need transparent and reliable insight into the macOS CoreAudio input pipeline.
